{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Importazioni e impostazioni"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "from PIL import Image, ImageOps\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "from queue import PriorityQueue\n",
    "import numpy as np\n",
    "import sys\n",
    "import itertools\n",
    "import uuid\n",
    "\n",
    "# Imposta il seed per la riproducibilità\n",
    "SEED = 10\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# Configurazione del logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Contatore globale per tenere traccia dell'ordine di scoperta dei file\n",
    "global_counter = itertools.count()\n",
    "\n",
    "# Output di impostazione iniziale\n",
    "print(\"Importazioni e impostazioni completate.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funzione per applicare trasformazioni casuali alle immagini"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "def apply_random_transform(image, unique_seed):\n",
    "    # Imposta un seed unico per ogni immagine basato su unique_seed\n",
    "    random.seed(unique_seed)\n",
    "    torch.manual_seed(unique_seed)\n",
    "\n",
    "    width, height = image.size\n",
    "\n",
    "    # Flip orizzontale con probabilità del 50%\n",
    "    if random.random() < 0.5:\n",
    "        image = ImageOps.mirror(image)\n",
    "\n",
    "    # Time Masking con probabilità del 50%\n",
    "    if random.random() < 0.5:\n",
    "        start_x = random.randint(0, width // 4)\n",
    "        end_x = random.randint(start_x, start_x + width // 4)\n",
    "        mask_color = (0, 0, 139)  # Colore blu scuro per mascherare\n",
    "        mask = Image.new('RGB', (end_x - start_x, height), mask_color)\n",
    "        image.paste(mask, (start_x, 0))\n",
    "\n",
    "    # Frequency Masking con probabilità del 50%\n",
    "    if random.random() < 0.5:\n",
    "        start_y = random.randint(0, height // 4)\n",
    "        end_y = random.randint(start_y, start_y + height // 4)\n",
    "        mask_color = (0, 0, 139)  # Colore blu scuro per mascherare\n",
    "        mask = Image.new('RGB', (width, end_y - start_y), mask_color)\n",
    "        image.paste(mask, (0, start_y))\n",
    "\n",
    "    # Livelli randomici di rumore con probabilità del 50%\n",
    "    if random.random() < 0.5:\n",
    "        noise_level = random.uniform(5, 15)  # Livelli di rumore tra 5 e 15\n",
    "        noise = torch.normal(0, noise_level, size=(height, width, 3))\n",
    "        image_array = torch.tensor(np.array(image)) + noise\n",
    "        image = Image.fromarray(np.uint8(torch.clamp(image_array, 0, 255).numpy()))\n",
    "\n",
    "    # Time shifting con probabilità del 50%\n",
    "    if random.random() < 0.5:\n",
    "        shift = random.randint(-width // 4, width // 4)  # Shift casuale\n",
    "        image_array = torch.tensor(np.array(image))\n",
    "        image_array = torch.roll(image_array, shifts=shift, dims=1)\n",
    "        image = Image.fromarray(image_array.numpy())\n",
    "\n",
    "    # Ritaglio per riportare l'immagine alla dimensione originale\n",
    "    image = ImageOps.fit(image, (width, height), method=0, bleed=0.0, centering=(0.5, 0.5))\n",
    "\n",
    "    return image\n",
    "\n",
    "# Output di impostazione della funzione\n",
    "print(\"Funzione di trasformazione impostata.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funzione per processare i file"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "def process_file(queue, pbar):\n",
    "    while not queue.empty():\n",
    "        _, (class_folder_path, sample, balanced_class_folder_path, is_augmented, unique_seed) = queue.get()\n",
    "        try:\n",
    "            sample_path = os.path.join(class_folder_path, sample)\n",
    "            image = Image.open(sample_path)\n",
    "\n",
    "            if is_augmented:\n",
    "                image = apply_random_transform(image, unique_seed)\n",
    "                sample_name, extension = os.path.splitext(sample)\n",
    "                transformed_sample_path = os.path.join(balanced_class_folder_path,\n",
    "                                                       f\"aug_{unique_seed}_{sample_name}{extension}\")\n",
    "            else:\n",
    "                transformed_sample_path = os.path.join(balanced_class_folder_path, sample)\n",
    "\n",
    "            image.save(transformed_sample_path)\n",
    "            image.close()\n",
    "            pbar.update(1)\n",
    "            queue.task_done()\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {sample_path}: {e}\")\n",
    "            queue.task_done()\n",
    "\n",
    "# Output di impostazione della funzione\n",
    "print(\"Funzione per processare i file impostata.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Funzione principale per processare gli scalogrammi"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def processing_scalograms(subfolder_paths, output_base_path, seed):\n",
    "    total_operations = 0\n",
    "    file_queue = PriorityQueue()  # Utilizza una coda prioritaria anziché FIFO\n",
    "\n",
    "    for subfolder_path in sorted(subfolder_paths):\n",
    "        for root, dirs, files in sorted(os.walk(subfolder_path), key=lambda x: x[0]):\n",
    "            original_samples = sorted([file for file in files if file.endswith(\".png\")])\n",
    "            num_samples = len(original_samples)\n",
    "            max_samples = 10934  # Modifica questo numero in base alle tue necessità\n",
    "\n",
    "            # Create the corresponding balanced folder path\n",
    "            relative_root = os.path.relpath(root, subfolder_path)\n",
    "            balanced_class_folder_path = os.path.join(output_base_path, relative_root)\n",
    "            os.makedirs(balanced_class_folder_path, exist_ok=True)\n",
    "\n",
    "            # Contatore locale per la cartella corrente\n",
    "            local_counter = itertools.count()\n",
    "\n",
    "            # Aggiungere campioni originali alla coda con priorità basata sull'ordine di scoperta\n",
    "            for sample in original_samples:\n",
    "                priority = next(global_counter)  # Priorità basata sull'ordine di scoperta\n",
    "                file_queue.put((priority, (root, sample, balanced_class_folder_path, False, None)))\n",
    "\n",
    "            # Se il numero di campioni è inferiore al massimo, esegui il sovracampionamento\n",
    "            if num_samples > 0 and num_samples < max_samples:\n",
    "                num_additional_samples = max_samples - num_samples\n",
    "\n",
    "                for i in range(num_additional_samples):\n",
    "                    sample_index = i % num_samples  # Usa un indice sequenziale\n",
    "                    sample = original_samples[sample_index]\n",
    "                    priority = next(global_counter)  # Priorità basata sull'ordine di scoperta\n",
    "                    unique_seed = seed + next(local_counter)  # Seed basato su SEED + contatore locale\n",
    "                    file_queue.put((priority, (root, sample, balanced_class_folder_path, True, unique_seed)))\n",
    "\n",
    "            total_operations += max_samples if num_samples < max_samples else num_samples\n",
    "\n",
    "    logging.info(f\"Starting processing with {total_operations} total operations\")\n",
    "\n",
    "    with tqdm(total=total_operations, desc=\"Processing all classes\") as pbar:\n",
    "        process_file(file_queue, pbar)\n",
    "\n",
    "    logging.info(\"Processing completed!\")\n",
    "\n",
    "print(\"Funzione principale impostata.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Esecuzione dello script principale"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    current_directory = os.getcwd()\n",
    "    dataset_folder_path = os.path.join(os.path.dirname(current_directory), \"/Users/irene.gaita/PycharmProjects/UnderwaterSoundsClassification/Normalizzazione\")\n",
    "    output_base_path = os.path.join(os.path.dirname(dataset_folder_path), \"/Users/irene.gaita/PycharmProjects/UnderwaterSoundsClassification/Bilanciamento_Scalogrammi\")\n",
    "    subfolders = [\"Target\", \"Non-Target\"]\n",
    "    subfolder_paths = [os.path.join(dataset_folder_path, subfolder) for subfolder in subfolders]\n",
    "\n",
    "    processing_scalograms(subfolder_paths, output_base_path, SEED)\n",
    "\n",
    "    sys.stdout.write(\"\\nProcessing completed!\\n\")\n",
    "\n",
    "print(\"Script principale eseguito.\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
