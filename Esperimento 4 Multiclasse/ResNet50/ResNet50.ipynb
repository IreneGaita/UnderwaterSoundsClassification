{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importazione delle Librerie",
   "id": "e8c89d0b47725cbe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:09.634506Z",
     "start_time": "2024-06-09T15:11:09.583954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "8478e5039820b523",
   "execution_count": 26,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Definizione della Classe CustomDataset",
   "id": "ee51021cd7fbe349"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:09.649458Z",
     "start_time": "2024-06-09T15:11:09.637512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, d))])\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for file in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    self.data.append(file_path)\n",
    "                    self.targets.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ],
   "id": "136cbb7c1ffbc204",
   "execution_count": 27,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funzioni per il Caricamento e il Salvataggio dei Checkpoint",
   "id": "c865b9266f401330"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:09.657437Z",
     "start_time": "2024-06-09T15:11:09.650971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_epoch += 1\n",
    "    metrics = checkpoint['metrics']\n",
    "    return model, optimizer, start_epoch, metrics\n",
    "\n",
    "def save_checkpoint(checkpoint_state, checkpoint_path):\n",
    "    torch.save(checkpoint_state, checkpoint_path)"
   ],
   "id": "5ddcda31c34e5445",
   "execution_count": 28,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Funzione per il Calcolo delle Metriche",
   "id": "26ab60083fdac3c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:09.666961Z",
     "start_time": "2024-06-09T15:11:09.658445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(loader, model, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(loader, desc=\"Calcolo metriche\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds)\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted', zero_division=1)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ],
   "id": "72af5645434cbed4",
   "execution_count": 29,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Preparazione dei Dati",
   "id": "2410dfcc6e435542"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:16.168985Z",
     "start_time": "2024-06-09T15:11:09.668271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Dataset import CustomDataset\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset_path = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Bilanciamento_Allenamento_Target'\n",
    "val_dataset_path = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Validazione_Target'\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset_path, transform=transform)\n",
    "val_dataset = CustomDataset(val_dataset_path, transform=transform)\n",
    "\n",
    "print(f\"Classi trovate nel dataset di addestramento: {train_dataset.classes}\")\n",
    "print(f\"Classi trovate nel dataset di validazione: {val_dataset.classes}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)"
   ],
   "id": "985a65320e0846a4",
   "execution_count": 30,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Inizializzazione del Modello",
   "id": "16b3b0c5b92f6d10"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:16.771311Z",
     "start_time": "2024-06-09T15:11:16.170500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_classes = len(train_dataset.classes)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for param in model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "scaler = GradScaler()"
   ],
   "id": "48c0643f032c710a",
   "execution_count": 31,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Caricamento del Checkpoint",
   "id": "4eae85f2c521e53f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T15:11:17.058848Z",
     "start_time": "2024-06-09T15:11:16.773318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "checkpoint_dir = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 4 Multiclasse\\ResNet50'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "latest_checkpoint = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth'))\n",
    "if latest_checkpoint:\n",
    "    latest_checkpoint = max(latest_checkpoint, key=os.path.getctime)\n",
    "    model, optimizer, start_epoch, metrics = load_checkpoint(latest_checkpoint, model, optimizer)\n",
    "else:\n",
    "    model, optimizer, start_epoch, metrics = model, optimizer, 0, []"
   ],
   "id": "71dae6eb1b957284",
   "execution_count": 32,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ciclo di Addestramento e Valutazione",
   "id": "316a6c78ca1096d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:07:44.497461Z",
     "start_time": "2024-06-09T15:11:17.060386Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_epochs = 50\n",
    "checkpoint_interval = 1\n",
    "gradient_accumulation_steps = 4\n",
    "patience = 5  # Numero di epoche senza miglioramenti prima di attivare l'early stopping\n",
    "performance_drop_patience = 5\n",
    "patience_counter = 0\n",
    "performance_drop_counter = 0\n",
    "last_val_metrics = None \n",
    "best_val_loss = float('inf')\n",
    "\n",
    "metrics_path = os.path.join(checkpoint_dir, 'training_metrics.csv')\n",
    "header_written = False\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        optimizer.zero_grad()\n",
    "        pbar_train = tqdm(train_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Addestramento\")\n",
    "        for step, (inputs, labels) in enumerate(pbar_train):\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            with autocast():\n",
    "                outputs = model(inputs)\n",
    "                train_loss = criterion(outputs, labels)\n",
    "            scaler.scale(train_loss).backward()\n",
    "\n",
    "            # Accumula gradienti\n",
    "            if (step + 1) % gradient_accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_train_loss += train_loss.item()\n",
    "            pbar_train.set_postfix({'Loss': running_train_loss / (step + 1)})\n",
    "\n",
    "        # Valutazione del modello ad ogni epoca\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        pbar_val = tqdm(val_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Valutazione\")\n",
    "        for inputs, labels in pbar_val:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            with torch.no_grad():\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss = criterion(outputs, labels)\n",
    "                running_val_loss += val_loss.item()\n",
    "                pbar_val.set_postfix({'Val Loss': running_val_loss / len(val_loader)})\n",
    "\n",
    "        # Calcola le metriche di addestramento e validazione\n",
    "        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(train_loader, model, device)\n",
    "        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(val_loader, model, device)\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "        # Stampa le metriche\n",
    "        print(f\"Epoca {epoch + 1}/{num_epochs} - \"\n",
    "              f\"Loss Addestramento: {epoch_train_loss:.4f} - Acc Addestramento: {train_accuracy:.4f} - \"\n",
    "              f\"Precision Addestramento: {train_precision:.4f} - Recall Addestramento: {train_recall:.4f} - \"\n",
    "              f\"F1 Addestramento: {train_f1:.4f} - \"\n",
    "              f\"Loss Valutazione: {epoch_val_loss:.4f} - Acc Valutazione: {val_accuracy:.4f} - \"\n",
    "              f\"Precision Valutazione: {val_precision:.4f} - Recall Valutazione: {val_recall:.4f} - F1 Valutazione: {val_f1:.4f}\")\n",
    "\n",
    "        # Aggiorna il file CSV con le metriche\n",
    "        with open(metrics_path, 'a', newline='') as csvfile:\n",
    "            fieldnames = ['epoch', 'train_loss', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1',\n",
    "                          'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "            # Scrittura dell'header solo se non è stato già scritto\n",
    "            if not header_written:\n",
    "                writer.writeheader()\n",
    "                header_written = True\n",
    "\n",
    "            # Scrittura delle metriche per l'epoca corrente\n",
    "            writer.writerow({\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"train_loss\": epoch_train_loss,\n",
    "                \"train_accuracy\": train_accuracy,\n",
    "                \"train_precision\": train_precision,\n",
    "                \"train_recall\": train_recall,\n",
    "                \"train_f1\": train_f1,\n",
    "                \"val_loss\": epoch_val_loss,\n",
    "                \"val_accuracy\": val_accuracy,\n",
    "                \"val_precision\": val_precision,\n",
    "                \"val_recall\": val_recall,\n",
    "                \"val_f1\": val_f1,\n",
    "            })\n",
    "\n",
    "        # Salva il checkpoint\n",
    "        checkpoint_state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch + 1}.pth')\n",
    "        save_checkpoint(checkpoint_state, checkpoint_path)\n",
    "        print(f\"Checkpoint salvato in: {checkpoint_path}\") \n",
    "        \n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "            performance_drop_counter = 0\n",
    "            checkpoint_state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'best_checkpoint.pth')\n",
    "            save_checkpoint(checkpoint_state, checkpoint_path)\n",
    "            print(f\"Miglior checkpoint salvato in: {checkpoint_path}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if last_val_metrics:\n",
    "            if (val_accuracy < last_val_metrics['val_accuracy'] and\n",
    "                    val_precision < last_val_metrics['val_precision'] and\n",
    "                    val_recall < last_val_metrics['val_recall'] and\n",
    "                    val_f1 < last_val_metrics['val_f1']):\n",
    "                performance_drop_counter += 1\n",
    "                print(f\"Prestazioni calate all'epoca {epoch + 1}, contatore di calo: {performance_drop_counter}\")\n",
    "            else:\n",
    "                performance_drop_counter = 0\n",
    "\n",
    "        last_val_metrics = {\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_f1\": val_f1,\n",
    "        }\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping attivato dopo {epoch + 1} epoche senza miglioramenti\")\n",
    "            break\n",
    "\n",
    "        if performance_drop_counter >= performance_drop_patience:\n",
    "            print(f\"Addestramento interrotto dopo {epoch + 1} epoche di calo delle prestazioni consecutive\")\n",
    "            break"
   ],
   "id": "b0b67a6082e2c8a8",
   "execution_count": 33,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Salvataggio del Modello Finale",
   "id": "3ed26159e5d7bac7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:07:44.665252Z",
     "start_time": "2024-06-09T16:07:44.510503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = os.path.join(checkpoint_dir, 'ResNet50_model_multiclass_final.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Modello finale salvato in: {model_path}\")"
   ],
   "id": "276e99cc6b43dd9f",
   "execution_count": 34,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creazione dei grafici",
   "id": "fcb42c9b31e3781b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:08:07.241808Z",
     "start_time": "2024-06-09T16:07:44.668257Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 4 Multiclasse\\ResNet50\\training_metrics.csv')\n",
    "\n",
    "# Estrai le metriche di addestramento e validazione\n",
    "train_metrics = ['train_loss', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1']\n",
    "val_metrics = ['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "\n",
    "# Crea un grafico separato per ogni coppia di metriche\n",
    "for train_metric, val_metric in zip(train_metrics, val_metrics):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['epoch'], df[train_metric], label='Train ' + train_metric.split('_')[1].capitalize())\n",
    "    plt.plot(df['epoch'], df[val_metric], label='Validation ' + val_metric.split('_')[1].capitalize())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title(train_metric.split('_')[1].capitalize() + ' Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "f3201b6ab76eb3d5",
   "execution_count": 35,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Testing",
   "id": "29a9056dbc02bfc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:09:23.473781Z",
     "start_time": "2024-06-09T16:08:07.242813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_model(model_path, num_classes, device):\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    model = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
    "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "model_path = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 4 Multiclasse\\ResNet50\\ResNet50_model_multiclass_final.pth'\n",
    "test_dataset_path = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Testing_Target'\n",
    "checkpoint_dir = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 4 Multiclasse\\ResNet50'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataset(test_dataset_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "num_classes = len(test_dataset.classes)\n",
    "model = load_model(model_path, num_classes, device)\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "running_test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, labels)\n",
    "        running_test_loss += test_loss.item()\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader)\n",
    "test_accuracy, test_precision, test_recall, test_f1 = calculate_metrics(test_loader, model, device)\n",
    "\n",
    "# Creazione del file CSV nella directory dei checkpoint\n",
    "csv_output_path = os.path.join(checkpoint_dir, 'test_results.csv')\n",
    "with open(csv_output_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['test_loss', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "\n",
    "print(f\"Risultati del testing salvati in: {csv_output_path}\")"
   ],
   "id": "3f1d7d3ae0d92bc4",
   "execution_count": 36,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creazione Grafici",
   "id": "23691fd7bc156640"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-09T16:09:23.605295Z",
     "start_time": "2024-06-09T16:09:23.477789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_results(csv_file):\n",
    "    results = {}\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            for key, value in row.items():\n",
    "                results[key] = float(value)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.bar(results.keys(), results.values(), color='skyblue')\n",
    "\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Testing Metrics')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 4 Multiclasse\\ResNet50\\test_results.csv'\n",
    "plot_results(csv_file)"
   ],
   "id": "df39f4782d917445",
   "execution_count": 37,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
