{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:22.971437Z",
     "start_time": "2024-06-03T11:18:22.968732Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "from PIL import Image\n",
    "import glob"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:22.981719Z",
     "start_time": "2024-06-03T11:18:22.977205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Classe del dataset personalizzato\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted(os.listdir(self.root_dir))\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for file in os.listdir(class_dir):\n",
    "                self.data.append(os.path.join(class_dir, file))\n",
    "                # Target per classificazione binaria: 0 o 1\n",
    "                self.targets.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ],
   "id": "aad3c08385333092",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:22.987750Z",
     "start_time": "2024-06-03T11:18:22.985513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trasformazioni\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ridimensiona a 224x224\n",
    "    transforms.ToTensor(),  # Converti in tensori PyTorch\n",
    "])"
   ],
   "id": "12cf50810151e58b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:22.998608Z",
     "start_time": "2024-06-03T11:18:22.996971Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Percorsi dei dataset\n",
    "train_dataset_path = '/Users/massimo/PycharmProjects/UnderwaterSoundsClassification/Normalizzazione'\n",
    "val_dataset_path = '/Users/massimo/PycharmProjects/UnderwaterSoundsClassification/Modello/Valutazione'\n",
    "test_dataset_path = '/Users/massimo/PycharmProjects/UnderwaterSoundsClassification/Modello/Testing'"
   ],
   "id": "144835189b30068b",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.047475Z",
     "start_time": "2024-06-03T11:18:23.013349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carica i dataset\n",
    "train_dataset = CustomDataset(train_dataset_path, transform=transform)\n",
    "val_dataset = CustomDataset(val_dataset_path, transform=transform)\n",
    "test_dataset = CustomDataset(test_dataset_path, transform=transform)"
   ],
   "id": "4efdae59984f7972",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.050072Z",
     "start_time": "2024-06-03T11:18:23.048218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "412e4dc06b419446",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.240362Z",
     "start_time": "2024-06-03T11:18:23.052224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Carica AlexNet pre-addestrato\n",
    "model = models.alexnet(pretrained=True)\n",
    "\n",
    "# Modifica il classificatore per la classificazione binaria\n",
    "model.classifier[6] = nn.Linear(model.classifier[6].in_features, 1)  # Output di 1 per BCEWithLogitsLoss\n",
    "\n",
    "# Congela i layer convoluzionali\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n"
   ],
   "id": "5112e637e0bd1c66",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.246723Z",
     "start_time": "2024-06-03T11:18:23.241141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funzione di loss e ottimizzatore\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)\n",
    "\n",
    "# Gestione del dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ],
   "id": "ca11745c65595c27",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.249193Z",
     "start_time": "2024-06-03T11:18:23.247262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funzione per calcolare le metriche\n",
    "def calculate_metrics(model, data_loader):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "    return accuracy, precision, recall, f1\n"
   ],
   "id": "daddb0cd62ed9bae",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.252041Z",
     "start_time": "2024-06-03T11:18:23.250121Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Funzione per salvare il checkpoint\n",
    "def save_checkpoint(state, filename):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "# Funzione per caricare il checkpoint\n",
    "def load_checkpoint(filename, model, optimizer):\n",
    "    if os.path.isfile(filename):\n",
    "        print(f\"Caricamento del checkpoint '{filename}'\")\n",
    "        checkpoint = torch.load(filename)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        metrics = checkpoint['metrics']\n",
    "        print(f\"Checkpoint caricato (epoca {checkpoint['epoch']})\")\n",
    "        return model, optimizer, start_epoch, metrics\n",
    "    else:\n",
    "        print(f\"Nessun checkpoint trovato a '{filename}'\")\n",
    "        return model, optimizer, 0, []\n"
   ],
   "id": "8350d8d0532fdc6b",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:18:23.254351Z",
     "start_time": "2024-06-03T11:18:23.252575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Directory dei checkpoint\n",
    "checkpoint_dir = 'checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# Carica l'ultimo checkpoint se esiste\n",
    "latest_checkpoint = glob.glob(os.path.join(checkpoint_dir, 'checkpoint_epoch_*.pth'))\n",
    "if latest_checkpoint:\n",
    "    latest_checkpoint = max(latest_checkpoint, key=os.path.getctime)\n",
    "    model, optimizer, start_epoch, metrics = load_checkpoint(latest_checkpoint, model, optimizer)\n",
    "else:\n",
    "    model, optimizer, start_epoch, metrics = model, optimizer, 0, []\n"
   ],
   "id": "4f655c946c59a359",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ciclo di addestramento con early stopping\n",
    "num_epochs = 25\n",
    "checkpoint_interval = 1  # Checkpoint ogni epoca\n",
    "patience = 5  # Numero di epoche senza miglioramenti dopo il quale interrompere l'addestramento\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    # Addestramento\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    pbar_train = tqdm(train_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Addestramento\")\n",
    "    for inputs, labels in pbar_train:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        train_loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        running_train_loss += train_loss.item()\n",
    "        pbar_train.set_postfix({'Loss': running_train_loss / len(train_loader)})\n",
    "\n",
    "    # Validazione\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    pbar_val = tqdm(val_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Validazione\")\n",
    "    for inputs, labels in pbar_val:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(inputs)\n",
    "            val_loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "            running_val_loss += val_loss.item()\n",
    "            pbar_val.set_postfix({'Val Loss': running_val_loss / len(val_loader)})\n",
    "\n",
    "    # Calcola le metriche sul set di validazione\n",
    "    val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(model, val_loader)\n",
    "    epoch_train_loss = running_train_loss / len(train_loader)\n",
    "    epoch_val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "    # Pulisci la barra di avanzamento prima di stampare\n",
    "    pbar_train.close()\n",
    "    pbar_val.close()\n",
    "    print(\n",
    "        f\"Epoca {epoch + 1}/{num_epochs} - Loss Addestramento: {epoch_train_loss:.4f} - Loss Validazione: {epoch_val_loss:.4f} - Accuratezza Validazione: {val_accuracy:.4f} - Precisione Validazione: {val_precision:.4f} - Recall Validazione: {val_recall:.4f} - F1 Validazione: {val_f1:.4f}\")\n",
    "\n",
    "    # Aggiungi le metriche\n",
    "    metrics.append({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": epoch_train_loss,\n",
    "        \"val_loss\": epoch_val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"val_precision\": val_precision,\n",
    "        \"val_recall\": val_recall,\n",
    "        \"val_f1\": val_f1\n",
    "    })\n",
    "\n",
    "    # Salva le metriche\n",
    "    metrics_path = os.path.join(checkpoint_dir, f'training_metrics_epoch_{epoch + 1}.csv')\n",
    "    with open(metrics_path, 'w', newline='') as csvfile:\n",
    "        fieldnames = ['epoch', 'train_loss', 'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for metric in metrics:\n",
    "            writer.writerow(metric)\n",
    "\n",
    "    print(f\"Metriche per l'epoca {epoch + 1} salvate in: {metrics_path}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        patience_counter = 0\n",
    "        # Salva il miglior checkpoint\n",
    "        checkpoint_state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'metrics': metrics\n",
    "        }\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'best_checkpoint.pth')\n",
    "        save_checkpoint(checkpoint_state, checkpoint_path)\n",
    "        print(f\"Miglior checkpoint salvato in: {checkpoint_path}\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping attivato dopo {epoch + 1} epoche\")\n",
    "        break"
   ],
   "id": "9406994c16c70b3f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-03T11:17:37.717880Z",
     "start_time": "2024-06-03T11:17:37.431342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Salva il modello addestrato\n",
    "torch.save(model.state_dict(), 'alexnet_model_binary_classification.pth')\n",
    "\n",
    "# Stampa il percorso del modello salvato\n",
    "model_path = os.path.abspath('alexnet_model_binary_classification.pth')\n",
    "print(f\"Modello salvato in: {model_path}\")"
   ],
   "id": "aa9e5d2b888c1d4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello salvato in: /Users/massimo/PycharmProjects/UnderwaterSoundsClassification/alexnet_model_binary_classification.pth\n"
     ]
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
