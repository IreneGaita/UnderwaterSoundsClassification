{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Librerie",
   "id": "add4ff65f2e72bc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:11.821642Z",
     "start_time": "2024-06-13T09:05:11.819370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "import os\n",
    "import csv\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "cf26ce291f2997a8",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inizializzazione dei parametri",
   "id": "df012642593ea125"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:11.849544Z",
     "start_time": "2024-06-13T09:05:11.847409Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Percorsi dei dataset di addestramento, validazione e test\n",
    "train_dataset_path = r'/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Train_Bil'\n",
    "val_dataset_path = r'/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Val_Norm'\n",
    "test_dataset_path = r'/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Testing_Norm'\n",
    "\n",
    "# Impostazione della dimensione del batch\n",
    "batch_size = 128\n",
    "\n",
    "# Numero di epoche di addestramento\n",
    "num_epochs = 50\n",
    "\n",
    "# Intervallo per il salvataggio dei checkpoint\n",
    "checkpoint_interval = 1\n",
    "\n",
    "# Parametri per l'early stopping\n",
    "patience = 5\n",
    "performance_drop_patience = 3\n",
    "\n",
    "# Numero di passaggi di accumulazione del gradiente\n",
    "gradient_accumulation_steps = 4\n",
    "\n",
    "# Impostazione del learning rate\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Directory per il salvataggio dei checkpoint\n",
    "checkpoint_dir = '/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Esperimento 1 Binary/EfficientNetB3'\n",
    "\n",
    "# Definizione della trasformazione per il preprocessing delle immagini\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ],
   "id": "1db3334d6612526f",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Definizione della Classe CustomDataset",
   "id": "542ebce3d1184414"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:11.853554Z",
     "start_time": "2024-06-13T09:05:11.850693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.classes = sorted([d for d in os.listdir(self.root_dir) if os.path.isdir(os.path.join(self.root_dir, d))])\n",
    "        self.data = []\n",
    "        self.targets = []\n",
    "\n",
    "        for idx, cls in enumerate(self.classes):\n",
    "            class_dir = os.path.join(self.root_dir, cls)\n",
    "            for file in os.listdir(class_dir):\n",
    "                file_path = os.path.join(class_dir, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    self.data.append(file_path)\n",
    "                    self.targets.append(idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, target"
   ],
   "id": "ee23db8bff31575b",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Funzioni per il Caricamento e il Salvataggio dei Checkpoint",
   "id": "530a72987f44d45e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:11.856118Z",
     "start_time": "2024-06-13T09:05:11.854254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_checkpoint(checkpoint_path, model, optimizer):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    start_epoch += 1\n",
    "    metrics = checkpoint['metrics']\n",
    "    return model, optimizer, start_epoch, metrics\n",
    "\n",
    "\n",
    "def save_checkpoint(checkpoint_state, checkpoint_path):\n",
    "    torch.save(checkpoint_state, checkpoint_path)"
   ],
   "id": "c024680307d7c3c5",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Funzione per il Calcolo delle Metriche",
   "id": "d86ee6e8ea0d1fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:11.859576Z",
     "start_time": "2024-06-13T09:05:11.857346Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_metrics(loader, model, device):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    pbar = tqdm(loader, desc=\"Calcolo metriche\")\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs).cpu().numpy()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_preds.extend(preds.round())\n",
    "            pbar.update()\n",
    "\n",
    "    all_labels = np.array(all_labels)\n",
    "    all_preds = np.array(all_preds)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds)\n",
    "    recall = recall_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    return accuracy, precision, recall, f1"
   ],
   "id": "2e6e39923ebaa7e2",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Preparazione dei Dati",
   "id": "62061fe28b54f2c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:12.599989Z",
     "start_time": "2024-06-13T09:05:11.859998Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from Dataset import CustomDataset\n",
    "\n",
    "train_dataset = CustomDataset(train_dataset_path, transform=transform)\n",
    "val_dataset = CustomDataset(val_dataset_path, transform=transform)\n",
    "\n",
    "print(f\"Classi trovate nel dataset di addestramento: {train_dataset.classes}\")\n",
    "print(f\"Classi trovate nel dataset di validazione: {val_dataset.classes}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)"
   ],
   "id": "10169baef73a1737",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classi trovate nel dataset di addestramento: ['Allenamento_Non-Target_Bil2', 'Allenamento_Target_Bil']\n",
      "Classi trovate nel dataset di validazione: ['Non-Target', 'Target']\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inizializzazione del Modello",
   "id": "fb93726f1bf57591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:12.768450Z",
     "start_time": "2024-06-13T09:05:12.600765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Caricamento del modello EfficientNet B3 pre-addestrato\n",
    "model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "\n",
    "# Modifica dell'ultimo strato per la classificazione binaria\n",
    "model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "scaler = GradScaler()\n"
   ],
   "id": "5f9c551bec2b9371",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Caricamento del Checkpoint",
   "id": "8a339f97d5cb93c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:05:12.771353Z",
     "start_time": "2024-06-13T09:05:12.768988Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "latest_checkpoint = glob.glob(os.path.join(checkpoint_dir, 'best_checkpoint.pth'))\n",
    "if latest_checkpoint:\n",
    "    latest_checkpoint = max(latest_checkpoint, key=os.path.getctime)\n",
    "    model, optimizer, start_epoch, metrics = load_checkpoint(latest_checkpoint, model, optimizer)\n",
    "else:\n",
    "    model, optimizer, start_epoch, metrics = model, optimizer, 0, []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "performance_drop_counter = 0\n",
    "last_val_metrics = None"
   ],
   "id": "41919a3c4e5c04d0",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Allenamento",
   "id": "cd23510b9041daa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:07:24.940056Z",
     "start_time": "2024-06-13T09:05:12.771889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for epoch in range(start_epoch, num_epochs):\n",
    "    model.train()\n",
    "    running_train_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "    pbar_train = tqdm(train_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Addestramento\")\n",
    "    for step, (inputs, labels) in enumerate(pbar_train):\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            train_loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        scaler.scale(train_loss).backward()\n",
    "\n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_train_loss += train_loss.item()\n",
    "        pbar_train.set_postfix({'Loss': running_train_loss / (step + 1)})\n",
    "        \n",
    "   # Validazione\n",
    "    if (epoch + 1) % checkpoint_interval == 0:\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        pbar_val = tqdm(val_loader, desc=f\"Epoca {epoch + 1}/{num_epochs} - Valutazione\")\n",
    "        for inputs, labels in pbar_val:\n",
    "            inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            with torch.no_grad():\n",
    "                with autocast():\n",
    "                    outputs = model(inputs)\n",
    "                    val_loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "                running_val_loss += val_loss.item()\n",
    "                pbar_val.set_postfix({'Val Loss': running_val_loss / len(val_loader)})\n",
    "\n",
    "        train_accuracy, train_precision, train_recall, train_f1 = calculate_metrics(train_loader, model, device)\n",
    "        val_accuracy, val_precision, val_recall, val_f1 = calculate_metrics(val_loader, model, device)\n",
    "        epoch_train_loss = running_train_loss / len(train_loader)\n",
    "        epoch_val_loss = running_val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoca {epoch + 1}/{num_epochs} - \"\n",
    "              f\"Loss Addestramento: {epoch_train_loss:.4f} - Acc Addestramento: {train_accuracy:.4f} - \"\n",
    "              f\"Precision Addestramento: {train_precision:.4f} - Recall Addestramento: {train_recall:.4f} - \"\n",
    "              f\"F1 Addestramento: {train_f1:.4f} - \"\n",
    "              f\"Loss Valutazione: {epoch_val_loss:.4f} - Acc Valutazione: {val_accuracy:.4f} - \"\n",
    "              f\"Precision Valutazione: {val_precision:.4f} - Recall Valutazione: {val_recall:.4f} - F1 Valutazione: {val_f1:.4f}\")\n",
    "\n",
    "        metrics.append({\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"train_loss\": epoch_train_loss,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"train_precision\": train_precision,\n",
    "            \"train_recall\": train_recall,\n",
    "            \"train_f1\": train_f1,\n",
    "            \"val_loss\": epoch_val_loss,\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_f1\": val_f1,\n",
    "        })\n",
    "\n",
    "        metrics_path = os.path.join(checkpoint_dir, f'training_metrics_epoch_{epoch + 1}.csv')\n",
    "        with open(metrics_path, 'w', newline='') as csvfile:\n",
    "            fieldnames = ['epoch', 'train_loss', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1',\n",
    "                          'val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            for metric in metrics:\n",
    "                writer.writerow(metric)\n",
    "\n",
    "        print(f\"Metriche per l'epoca {epoch + 1} salvate in: {metrics_path}\")\n",
    "\n",
    "        if epoch_val_loss < best_val_loss:\n",
    "            best_val_loss = epoch_val_loss\n",
    "            patience_counter = 0\n",
    "            performance_drop_counter = 0\n",
    "            checkpoint_state = {\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'metrics': metrics\n",
    "            }\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'best_checkpoint.pth')\n",
    "            save_checkpoint(checkpoint_state, checkpoint_path)\n",
    "            print(f\"Miglior checkpoint salvato in: {checkpoint_path}\")\n",
    "        \n",
    "        # Early Stopping\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if last_val_metrics:\n",
    "            if (val_accuracy < last_val_metrics['val_accuracy'] and\n",
    "                    val_precision < last_val_metrics['val_precision'] and\n",
    "                    val_recall < last_val_metrics['val_recall'] and\n",
    "                    val_f1 < last_val_metrics['val_f1']):\n",
    "                performance_drop_counter += 1\n",
    "                print(f\"Prestazioni calate all'epoca {epoch + 1}, contatore di calo: {performance_drop_counter}\")\n",
    "            else:\n",
    "                performance_drop_counter = 0\n",
    "\n",
    "        last_val_metrics = {\n",
    "            \"val_accuracy\": val_accuracy,\n",
    "            \"val_precision\": val_precision,\n",
    "            \"val_recall\": val_recall,\n",
    "            \"val_f1\": val_f1,\n",
    "        }\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(f\"Early stopping attivato dopo {epoch + 1} epoche senza miglioramenti\")\n",
    "            break\n",
    "\n",
    "        if performance_drop_counter >= performance_drop_patience:\n",
    "            print(f\"Addestramento interrotto dopo {epoch + 1} epoche di calo delle prestazioni consecutive\")\n",
    "            break\n"
   ],
   "id": "5cde7b3cc17f2562",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoca 1/50 - Addestramento:   1%|          | 12/1642 [02:02<4:27:50,  9.86s/it, Loss=0.686]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11c96ff60>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "Epoca 1/50 - Addestramento:   1%|          | 12/1642 [02:12<4:58:58, 11.01s/it, Loss=0.686]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m inputs, labels \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device, non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m), labels\u001B[38;5;241m.\u001B[39mto(device, non_blocking\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m autocast():\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[1;32m     10\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels\u001B[38;5;241m.\u001B[39mfloat()\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m     11\u001B[0m scaler\u001B[38;5;241m.\u001B[39mscale(train_loss)\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torchvision/models/efficientnet.py:343\u001B[0m, in \u001B[0;36mEfficientNet.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    342\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_impl(x)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torchvision/models/efficientnet.py:333\u001B[0m, in \u001B[0;36mEfficientNet._forward_impl\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_forward_impl\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 333\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfeatures(x)\n\u001B[1;32m    335\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mavgpool(x)\n\u001B[1;32m    336\u001B[0m     x \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mflatten(x, \u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torchvision/models/efficientnet.py:164\u001B[0m, in \u001B[0;36mMBConv.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 164\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39muse_res_connect:\n\u001B[1;32m    166\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstochastic_depth(result)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1530\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1531\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1536\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1537\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1538\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1539\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1540\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1541\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1543\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1544\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m/opt/anaconda3/envs/UnderwaterSounds/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Salvataggio del Modello Finale",
   "id": "1440adef89b6e4f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path ='/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Esperimento 1 Binary/EfficientNetB3/EfficientNetB3_binary_classification.pth'\n",
    "torch.save(model.state_dict(), model_path)\n",
    "    \n",
    "print(f\"Modello salvato in: {model_path}\")"
   ],
   "id": "724661f23f8ad966",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione dei grafici di Addestramento e Validazione",
   "id": "f0fc06bb982d56c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Leggi i dati dal file CSV\n",
    "df = pd.read_csv(r'C:\\Users\\biagi\\PycharmProjects\\gruppo17\\Esperimento 1 Binary\\AlexNet_Binary\\training_metrics.csv')\n",
    "\n",
    "# Estrai le metriche di addestramento e validazione\n",
    "train_metrics = ['train_loss', 'train_accuracy', 'train_precision', 'train_recall', 'train_f1']\n",
    "val_metrics = ['val_loss', 'val_accuracy', 'val_precision', 'val_recall', 'val_f1']\n",
    "\n",
    "# Crea un grafico separato per ogni coppia di metriche\n",
    "for train_metric, val_metric in zip(train_metrics, val_metrics):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(df['epoch'], df[train_metric], label='Train ' + train_metric.split('_')[1].capitalize())\n",
    "    plt.plot(df['epoch'], df[val_metric], label='Validation ' + val_metric.split('_')[1].capitalize())\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Metric Value')\n",
    "    plt.title(train_metric.split('_')[1].capitalize() + ' Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "id": "3c16532c5033232a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing",
   "id": "31d6d70139cd9a61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_model(model_path, device):\n",
    "   # Caricamento del modello EfficientNet B3 pre-addestrato\n",
    "    model = models.efficientnet_b3(weights=models.EfficientNet_B3_Weights.DEFAULT)\n",
    "\n",
    "    # Modifica dell'ultimo strato per la classificazione binaria\n",
    "    model.classifier[1] = nn.Linear(model.classifier[1].in_features, 1)\n",
    "   \n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataset(test_dataset_path, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "model = load_model(model_path, device)\n",
    "model.eval()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "running_test_loss = 0.0\n",
    "all_labels = []\n",
    "all_outputs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "        outputs = model(inputs)\n",
    "        test_loss = criterion(outputs, labels.float().view(-1, 1))\n",
    "        running_test_loss += test_loss.item()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_outputs.extend(outputs.cpu().numpy())\n",
    "\n",
    "test_loss = running_test_loss / len(test_loader)\n",
    "test_accuracy, test_precision, test_recall, test_f1 = calculate_metrics(test_loader, model, device)\n",
    "\n",
    "# Creazione del file CSV nella directory dei checkpoint\n",
    "csv_output_path = os.path.join(checkpoint_dir, 'test_results.csv')\n",
    "with open(csv_output_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['test_loss', 'test_accuracy', 'test_precision', 'test_recall', 'test_f1']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerow({\n",
    "        'test_loss': test_loss,\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1\n",
    "    })\n",
    "\n",
    "print(f\"Risultati del testing salvati in: {csv_output_path}\")"
   ],
   "id": "3efeda04c6e8fd39"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Creazione Grafici Testing",
   "id": "bb551a267b955327"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-11T18:36:30.297641Z",
     "start_time": "2024-06-11T18:36:30.225740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_results(csv_file):\n",
    "    results = {}\n",
    "    with open(csv_file, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            for key, value in row.items():\n",
    "                results[key] = float(value)\n",
    "\n",
    "    # Plotting\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "    # Bar plot\n",
    "    ax.bar(results.keys(), results.values(), color='skyblue')\n",
    "\n",
    "    ax.set_ylabel('Value')\n",
    "    ax.set_title('Testing Metrics')\n",
    "    plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Esempio di utilizzo\n",
    "csv_file = r'/Users/massimo/PycharmProjects/EnderwaterSoundsClassification/Esperimento 1 Binary/AlexNet_Binary/test_results.csv'\n",
    "plot_results(csv_file)\n"
   ],
   "id": "f4f47e353636e2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
